{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "gb-vpp-convlstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMZt80fEZcnDEYKDkXGkCP3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mavillan/gb-vpp/blob/main/models/gb-vpp-convlstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_q1A_uRF_Jc",
        "outputId": "cce0d572-1a85-462a-f99c-defb84702d97"
      },
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "!pip install --upgrade kaggle > /dev/null 2>&1\n",
        "!mkdir -p ~/.kaggle/ && cp /content/drive/MyDrive/kaggle/kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsJC-_8FViFK",
        "outputId": "18b60689-7080-46b1-e52b-64980994bfe6"
      },
      "source": [
        "!pip uninstall -y tensorflow \n",
        "!pip install tensorflow==2.4.3 > /dev/null 2>&1\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.6.0\n",
            "Uninstalling tensorflow-2.6.0:\n",
            "  Successfully uninstalled tensorflow-2.6.0\n",
            "Tensorflow version 2.4.3\n",
            "Running on TPU  ['10.120.148.34:8470']\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.120.148.34:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.120.148.34:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFa9wQ2IGrRR",
        "outputId": "d8c8274e-6ea4-4a98-e9cd-a23c88e3f887"
      },
      "source": [
        "!mkdir -p input/\n",
        "!kaggle competitions download -c ventilator-pressure-prediction -p input/ --force\n",
        "\n",
        "!unzip -o input/sample_submission.csv.zip -d input/\n",
        "!unzip -o input/train.csv.zip -d input/\n",
        "!unzip -o input/test.csv.zip -d input/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading sample_submission.csv.zip to input\n",
            "  0% 0.00/8.50M [00:00<?, ?B/s]\n",
            "100% 8.50M/8.50M [00:00<00:00, 78.2MB/s]\n",
            "Downloading train.csv.zip to input\n",
            " 91% 127M/139M [00:01<00:00, 109MB/s] \n",
            "100% 139M/139M [00:01<00:00, 87.4MB/s]\n",
            "Downloading test.csv.zip to input\n",
            " 90% 68.0M/75.4M [00:00<00:00, 79.0MB/s]\n",
            "100% 75.4M/75.4M [00:00<00:00, 96.8MB/s]\n",
            "Archive:  input/sample_submission.csv.zip\n",
            "  inflating: input/sample_submission.csv  \n",
            "Archive:  input/train.csv.zip\n",
            "  inflating: input/train.csv         \n",
            "Archive:  input/test.csv.zip\n",
            "  inflating: input/test.csv          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hEWJqeFGonH"
      },
      "source": [
        "input_path = \"input\"\n",
        "subs_path = \"/content/drive/MyDrive/kaggle/gb-vpp/subs\"\n",
        "results_path = \"/content/drive/MyDrive/kaggle/gb-vpp/results\"\n",
        "artifacts_path = \"/content/drive/MyDrive/kaggle/gb-vpp/artifacts\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD2JeSsUJjyJ"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdrij3cGJi79"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.preprocessing import RobustScaler, normalize\n",
        "from sklearn.model_selection import train_test_split, GroupKFold, KFold\n",
        "\n",
        "from IPython.display import display"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhdojM-wJ9HM"
      },
      "source": [
        "***\n",
        "## data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuScHGBrhkWT"
      },
      "source": [
        "SEQ_LEN = 80"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc0m-MxQJ02u"
      },
      "source": [
        "train_raw = pd.read_csv(f'{input_path}/train.csv')\n",
        "test_raw = pd.read_csv(f'{input_path}/test.csv')\n",
        "submission = pd.read_csv(f'{input_path}/sample_submission.csv')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLMXEGnoPTCL"
      },
      "source": [
        "mapping = {j:i for i,j in enumerate(train_raw.breath_id.unique())}\n",
        "train_raw[\"breath_id\"] = train_raw.breath_id.map(mapping)\n",
        "\n",
        "if SEQ_LEN < 80:\n",
        "\n",
        "    train_raw = (\n",
        "        train_raw\n",
        "        .sort_values([\"breath_id\",\"time_step\"])\n",
        "        .groupby(\"breath_id\")\n",
        "        .head(SEQ_LEN)\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "    test_raw = (\n",
        "        test_raw\n",
        "        .sort_values([\"breath_id\",\"time_step\"])\n",
        "        .groupby(\"breath_id\")\n",
        "        .head(SEQ_LEN)\n",
        "        .reset_index(drop=True)\n",
        "    )"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Izfe9H4mvCpn"
      },
      "source": [
        "def add_features(df):\n",
        "    df['area'] = df['time_step'] * df['u_in']\n",
        "    df['area'] = df.groupby('breath_id')['area'].cumsum()\n",
        "    \n",
        "    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n",
        "    \n",
        "    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n",
        "    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n",
        "    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n",
        "    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n",
        "    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n",
        "    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n",
        "    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n",
        "    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n",
        "    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n",
        "    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n",
        "    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n",
        "    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n",
        "    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n",
        "    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n",
        "    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n",
        "    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n",
        "    df = df.fillna(0)\n",
        "    \n",
        "    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n",
        "    df['breath_id__u_out__max'] = df.groupby(['breath_id'])['u_out'].transform('max')\n",
        "    \n",
        "    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n",
        "    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n",
        "    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n",
        "    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n",
        "    \n",
        "    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n",
        "    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n",
        "    \n",
        "    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n",
        "    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n",
        "    \n",
        "    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n",
        "    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n",
        "    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n",
        "    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n",
        "    df['cross']= df['u_in']*df['u_out']\n",
        "    df['cross2']= df['time_step']*df['u_out']\n",
        "    \n",
        "    df['R'] = df['R'].astype(str)\n",
        "    df['C'] = df['C'].astype(str)\n",
        "    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n",
        "    df = pd.get_dummies(df)\n",
        "    return df\n",
        "\n",
        "train = add_features(train_raw)\n",
        "test = add_features(test_raw)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dr-VSykkKJoJ"
      },
      "source": [
        "# def compute_feats(dataframe):\n",
        "#     dataframe = dataframe.copy()\n",
        "\n",
        "#     # time features\n",
        "#     dataframe[\"time_diff\"] = dataframe.groupby(\"breath_id\")[\"time_step\"].diff()\n",
        "#     dataframe['time_since_expiratory']= dataframe['time_step'] * dataframe['u_out']\n",
        "\n",
        "#     # lag features\n",
        "#     lags = [1,2]\n",
        "#     for lag in lags:\n",
        "#         dataframe[f\"u_in_lag{lag}\"] = dataframe.groupby(\"breath_id\")[\"u_in\"].shift(lag).fillna(0)\n",
        "\n",
        "#     # stats on u_in\n",
        "#     dataframe[\"u_in_cumsum\"] = dataframe.groupby(\"breath_id\")[\"u_in\"].cumsum()\n",
        "#     dataframe['u_in_cummean'] =dataframe['u_in_cumsum'] / (dataframe.groupby(\"breath_id\")[\"id\"].cumcount()+1)\n",
        "#     #dataframe['u_in_last'] = dataframe.groupby('breath_id')['u_in'].transform('last')\n",
        "#     dataframe['cross1']= dataframe['u_in'] * dataframe['u_out']\n",
        "#     dataframe['cross2']= dataframe['u_in'] * (1 - dataframe['u_out'])\n",
        "\n",
        "#     dataframe['area'] = dataframe['time_step'] * dataframe['u_in']\n",
        "#     dataframe['area'] = dataframe.groupby('breath_id')['area'].cumsum()\n",
        "    \n",
        "#     dataframe['vol_diff'] = (dataframe['time_diff']*dataframe['u_in']).fillna(0)\n",
        "#     dataframe['vol_diff_cumsum'] = dataframe.groupby('breath_id')['vol_diff'].cumsum()\n",
        "\n",
        "#     # gradients of u_in\n",
        "#     def compute_grad_1st(df):\n",
        "#         return np.gradient(df.u_in, 100*df.time_step)\n",
        "#     def compute_grad_2nd(df):\n",
        "#         return np.gradient(df.grad_1st, 100*df.time_step)\n",
        "\n",
        "#     gb_result = dataframe.groupby(\"breath_id\").apply(compute_grad_1st)\n",
        "#     dataframe[\"grad_1st\"] = np.concatenate(gb_result.values)\n",
        "#     gb_result = dataframe.groupby(\"breath_id\").apply(compute_grad_2nd)\n",
        "#     dataframe[\"grad_2nd\"] = np.concatenate(gb_result.values)\n",
        "\n",
        "#     # nan filling\n",
        "#     dataframe[\"time_diff\"] = dataframe[\"time_diff\"].fillna(method=\"bfill\")\n",
        "    \n",
        "#     # ohe of R&C values    \n",
        "#     dataframe['R'] = dataframe['R'].astype(str)\n",
        "#     dataframe['C'] = dataframe['C'].astype(str)\n",
        "#     dataframe['RC'] = dataframe['R']+dataframe['C']\n",
        "#     dataframe = pd.get_dummies(dataframe)\n",
        "#     return dataframe\n",
        "\n",
        "# train = compute_feats(train_raw)\n",
        "# test  = compute_feats(test_raw)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FydxTC2zKb3r"
      },
      "source": [
        "targets = train[['pressure']].to_numpy().reshape(-1, SEQ_LEN)\n",
        "\n",
        "cols_to_exclude_train = exclude = [\"id\",\"breath_id\",\"pressure\"]\n",
        "cols_to_exclude_test = exclude = [\"id\",\"breath_id\",]\n",
        "\n",
        "train.drop(cols_to_exclude_train, axis=1, inplace=True)\n",
        "test.drop(cols_to_exclude_test, axis=1, inplace=True)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmiLTm8gK1eG"
      },
      "source": [
        "scaler = RobustScaler()\n",
        "train = scaler.fit_transform(train)\n",
        "test = scaler.transform(test)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkjljVxeLIsu"
      },
      "source": [
        "train = train.reshape(-1, SEQ_LEN, train.shape[-1])\n",
        "test = test.reshape(-1, SEQ_LEN, train.shape[-1])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7-mHNoyLkNR"
      },
      "source": [
        "***\n",
        "## model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzUU2cq3EUXc"
      },
      "source": [
        "def build_model(input_dim):\n",
        "    with tpu_strategy.scope():   \n",
        "        inputs = layers.Input(shape = input_dim)\n",
        "    \n",
        "        #h1 = layers.Bidirectional(layers.LSTM(1024, return_sequences=True))(inputs)\n",
        "        h1 = layers.Dense(4096, activation = 'swish')(inputs)\n",
        "        h1 = tf.reshape(h1, shape=(-1,80,256,1,16))\n",
        "\n",
        "        h2 = layers.Bidirectional(layers.ConvLSTM2D(filters=256, kernel_size=(1,5), padding=\"same\", return_sequences=True, data_format=\"channels_first\"))(h1)\n",
        "        h2 = layers.AveragePooling3D(pool_size=(1,1,2), padding='valid', data_format=\"channels_first\")(h2)\n",
        "\n",
        "        h3 = layers.Bidirectional(layers.ConvLSTM2D(filters=256, kernel_size=(1,3), padding=\"same\", return_sequences=True, data_format=\"channels_first\"))(h2)\n",
        "        h3 = layers.AveragePooling3D(pool_size=(1,1,2), padding='valid', data_format=\"channels_first\")(h3)\n",
        "\n",
        "        h4 = layers.Bidirectional(layers.ConvLSTM2D(filters=128, kernel_size=(1,3), padding=\"same\", return_sequences=True, data_format=\"channels_first\"))(h3)\n",
        "        h4 = layers.AveragePooling3D(pool_size=(1,1,2), padding='valid', data_format=\"channels_first\")(h4)\n",
        "\n",
        "        h5 = layers.Bidirectional(layers.ConvLSTM2D(filters=64, kernel_size=(1,5), padding=\"same\", return_sequences=True, data_format=\"channels_first\"))(h4)\n",
        "        h5 = layers.MaxPooling3D(pool_size=(1,1,2), padding='valid', data_format=\"channels_first\")(h5)\n",
        "        h5 = tf.reshape(h5, shape=(-1,80,1024))\n",
        "\n",
        "        out = layers.Dense(128, activation = 'selu')(h5)\n",
        "        out = layers.Dense(1)(out)\n",
        "        \n",
        "        model = keras.Model(inputs, out)\n",
        "        model.compile(optimizer=\"adam\", loss=\"mae\")\n",
        "           \n",
        "    return model  "
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "vwqKrPZ-mzDq",
        "outputId": "37488996-857e-487d-d196-3fffc4d974eb"
      },
      "source": [
        "model = build_model(input_dim=train.shape[-2:])\n",
        "display(model.summary())"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_14 (InputLayer)        [(None, 80, 50)]          0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 80, 4096)          208896    \n",
            "_________________________________________________________________\n",
            "tf.reshape_23 (TFOpLambda)   (None, 80, 256, 1, 16)    0         \n",
            "_________________________________________________________________\n",
            "bidirectional_47 (Bidirectio (None, 80, 256, 1, 32)    5244928   \n",
            "_________________________________________________________________\n",
            "average_pooling3d_27 (Averag (None, 80, 256, 1, 16)    0         \n",
            "_________________________________________________________________\n",
            "bidirectional_48 (Bidirectio (None, 80, 256, 1, 32)    3147776   \n",
            "_________________________________________________________________\n",
            "average_pooling3d_28 (Averag (None, 80, 256, 1, 16)    0         \n",
            "_________________________________________________________________\n",
            "bidirectional_49 (Bidirectio (None, 80, 128, 1, 32)    1180672   \n",
            "_________________________________________________________________\n",
            "average_pooling3d_29 (Averag (None, 80, 128, 1, 16)    0         \n",
            "_________________________________________________________________\n",
            "bidirectional_50 (Bidirectio (None, 80, 64, 1, 32)     492032    \n",
            "_________________________________________________________________\n",
            "max_pooling3d_5 (MaxPooling3 (None, 80, 64, 1, 16)     0         \n",
            "_________________________________________________________________\n",
            "tf.reshape_24 (TFOpLambda)   (None, 80, 1024)          0         \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 80, 128)           131200    \n",
            "_________________________________________________________________\n",
            "dense_33 (Dense)             (None, 80, 1)             129       \n",
            "=================================================================\n",
            "Total params: 10,405,633\n",
            "Trainable params: 10,405,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pbhtf4DM1JaY",
        "outputId": "c73167e1-e9ee-4394-b1ea-460bc623c698"
      },
      "source": [
        "EPOCH = 300\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=2021)\n",
        "models_by_fold = list()\n",
        "\n",
        "oof = train_raw[[\"id\",\"breath_id\",\"u_out\",\"pressure\"]].copy()\n",
        "\n",
        "for fold, (train_idx,valid_idx) in enumerate(kf.split(train, targets)):\n",
        "\n",
        "    print(f\" Fold: {fold+1} \".center(80, \"-\"))\n",
        "    X_train, X_valid = train[train_idx], train[valid_idx]\n",
        "    y_train, y_valid = targets[train_idx], targets[valid_idx]\n",
        "    \n",
        "    model = build_model(input_dim=train.shape[-2:])\n",
        "    display(model.summary())\n",
        "\n",
        "    #scheduler = ExponentialDecay(\n",
        "    #    initial_learning_rate=1e-3, \n",
        "    #    decay_steps=EPOCH*((len(train)*0.8)/BATCH_SIZE), \n",
        "    #    decay_rate=1e-5\n",
        "    #)\n",
        "    #lr = LearningRateScheduler(scheduler, verbose=1)\n",
        "    #lr = OneCycleScheduler(\n",
        "    #    lr_max = 1e-3,\n",
        "    #    steps = EPOCH*(X_train.shape[0]/BATCH_SIZE),\n",
        "    #    phase_1_pct = 0.2,\n",
        "    #    init_div_factor = 1e1,\n",
        "    #    final_div_factor = 1e2,\n",
        "    #)\n",
        "    lr = ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\", \n",
        "        factor=0.8, \n",
        "        patience=10, \n",
        "        verbose=1\n",
        "    )\n",
        "    es = EarlyStopping(\n",
        "        monitor='val_loss', \n",
        "        mode='min', \n",
        "        patience=35, \n",
        "        verbose=1,\n",
        "        restore_best_weights=True,\n",
        "    )\n",
        "    history = model.fit(\n",
        "        X_train, \n",
        "        y_train, \n",
        "        validation_data=(X_valid, y_valid), \n",
        "        epochs=EPOCH, \n",
        "        batch_size=BATCH_SIZE, \n",
        "        callbacks=[lr,es],\n",
        "        verbose=1,\n",
        "    )\n",
        "    models_by_fold.append(model)\n",
        "\n",
        "    # generate the oof predictions\n",
        "    x_valid_tf = tf.convert_to_tensor(X_valid, dtype=tf.float32)\n",
        "    oof_preds = model.call(x_valid_tf, training=False).numpy().squeeze()\n",
        "    idx = oof.query(\"breath_id in @valid_idx\").index\n",
        "    oof.loc[idx, \"pred\"] = oof_preds.ravel()\n",
        "\n",
        "    plt.figure(figsize=(12,5))\n",
        "    plt.plot(history.history[\"loss\"], \"o--\", label=\"loss\")\n",
        "    plt.plot(history.history[\"val_loss\"], \"o--\", label=\"val_loss\")\n",
        "    plt.grid()\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.show()\n",
        "    \n",
        "    plt.figure(figsize=(12,5))\n",
        "    plt.plot(history.history[\"loss\"][50:], \"o--\", label=\"loss\")\n",
        "    plt.plot(history.history[\"val_loss\"][50:], \"o--\", label=\"val_loss\")\n",
        "    plt.grid()\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.show()\n",
        "\n",
        "    break\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------- Fold: 1 ------------------------------------\n",
            "Model: \"model_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_17 (InputLayer)        [(None, 80, 50)]          0         \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 80, 4096)          208896    \n",
            "_________________________________________________________________\n",
            "tf.reshape_29 (TFOpLambda)   (None, 80, 256, 1, 16)    0         \n",
            "_________________________________________________________________\n",
            "bidirectional_59 (Bidirectio (None, 80, 256, 1, 32)    5244928   \n",
            "_________________________________________________________________\n",
            "average_pooling3d_36 (Averag (None, 80, 256, 1, 16)    0         \n",
            "_________________________________________________________________\n",
            "bidirectional_60 (Bidirectio (None, 80, 256, 1, 32)    3147776   \n",
            "_________________________________________________________________\n",
            "average_pooling3d_37 (Averag (None, 80, 256, 1, 16)    0         \n",
            "_________________________________________________________________\n",
            "bidirectional_61 (Bidirectio (None, 80, 128, 1, 32)    1180672   \n",
            "_________________________________________________________________\n",
            "average_pooling3d_38 (Averag (None, 80, 128, 1, 16)    0         \n",
            "_________________________________________________________________\n",
            "bidirectional_62 (Bidirectio (None, 80, 64, 1, 32)     492032    \n",
            "_________________________________________________________________\n",
            "max_pooling3d_8 (MaxPooling3 (None, 80, 64, 1, 16)     0         \n",
            "_________________________________________________________________\n",
            "tf.reshape_30 (TFOpLambda)   (None, 80, 1024)          0         \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 80, 128)           131200    \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 80, 1)             129       \n",
            "=================================================================\n",
            "Total params: 10,405,633\n",
            "Trainable params: 10,405,633\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "236/236 [==============================] - 145s 463ms/step - loss: 2.7276 - val_loss: 0.8152\n",
            "Epoch 2/300\n",
            "236/236 [==============================] - 81s 342ms/step - loss: 0.7126 - val_loss: 0.5723\n",
            "Epoch 3/300\n",
            "236/236 [==============================] - 81s 342ms/step - loss: 0.5612 - val_loss: 0.5037\n",
            "Epoch 4/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.4956 - val_loss: 0.4344\n",
            "Epoch 5/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.4509 - val_loss: 0.4152\n",
            "Epoch 6/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.4247 - val_loss: 0.4028\n",
            "Epoch 7/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.4058 - val_loss: 0.4805\n",
            "Epoch 8/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.3839 - val_loss: 0.3776\n",
            "Epoch 9/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.3750 - val_loss: 0.3529\n",
            "Epoch 10/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.3539 - val_loss: 0.3418\n",
            "Epoch 11/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.3553 - val_loss: 0.3405\n",
            "Epoch 12/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.3300 - val_loss: 0.3439\n",
            "Epoch 13/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.3263 - val_loss: 0.3480\n",
            "Epoch 14/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.3177 - val_loss: 0.3368\n",
            "Epoch 15/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.3117 - val_loss: 0.3542\n",
            "Epoch 16/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.3348 - val_loss: 0.3150\n",
            "Epoch 17/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.3034 - val_loss: 0.3123\n",
            "Epoch 18/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.3095 - val_loss: 0.3255\n",
            "Epoch 19/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.3022 - val_loss: 0.3260\n",
            "Epoch 20/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.3065 - val_loss: 0.3464\n",
            "Epoch 21/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.3062 - val_loss: 0.3002\n",
            "Epoch 22/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.2914 - val_loss: 0.2894\n",
            "Epoch 23/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.2721 - val_loss: 0.2771\n",
            "Epoch 24/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.2696 - val_loss: 0.2985\n",
            "Epoch 25/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.2676 - val_loss: 0.3124\n",
            "Epoch 26/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.2859 - val_loss: 0.2769\n",
            "Epoch 27/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.2652 - val_loss: 0.2905\n",
            "Epoch 28/300\n",
            "236/236 [==============================] - 81s 342ms/step - loss: 0.2635 - val_loss: 0.2624\n",
            "Epoch 29/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.2539 - val_loss: 0.2521\n",
            "Epoch 30/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.2561 - val_loss: 0.3043\n",
            "Epoch 31/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.2807 - val_loss: 0.2869\n",
            "Epoch 32/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.2563 - val_loss: 0.2776\n",
            "Epoch 33/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.2477 - val_loss: 0.2519\n",
            "Epoch 34/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.2437 - val_loss: 0.2657\n",
            "Epoch 35/300\n",
            "236/236 [==============================] - 81s 342ms/step - loss: 0.2442 - val_loss: 0.2506\n",
            "Epoch 36/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.2460 - val_loss: 0.2562\n",
            "Epoch 37/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.2363 - val_loss: 0.2490\n",
            "Epoch 38/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.2319 - val_loss: 0.2797\n",
            "Epoch 39/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.2509 - val_loss: 0.2546\n",
            "Epoch 40/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.2339 - val_loss: 0.2519\n",
            "Epoch 41/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.2342 - val_loss: 0.2532\n",
            "Epoch 42/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.2365 - val_loss: 0.2469\n",
            "Epoch 43/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.2360 - val_loss: 0.2503\n",
            "Epoch 44/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.2466 - val_loss: 0.2480\n",
            "Epoch 45/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.2223 - val_loss: 0.2507\n",
            "Epoch 46/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.2330 - val_loss: 0.2658\n",
            "Epoch 47/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.2335 - val_loss: 0.2485\n",
            "Epoch 48/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.2353 - val_loss: 0.2443\n",
            "Epoch 49/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.2294 - val_loss: 0.2580\n",
            "Epoch 50/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.2274 - val_loss: 0.2441\n",
            "Epoch 51/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.2245 - val_loss: 0.2780\n",
            "Epoch 52/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.2315 - val_loss: 0.2461\n",
            "Epoch 53/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.2475 - val_loss: 0.2372\n",
            "Epoch 54/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.2179 - val_loss: 0.2512\n",
            "Epoch 55/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.2223 - val_loss: 0.2284\n",
            "Epoch 56/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.2124 - val_loss: 0.2301\n",
            "Epoch 57/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.2072 - val_loss: 0.2205\n",
            "Epoch 58/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.2006 - val_loss: 0.2294\n",
            "Epoch 59/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.2046 - val_loss: 0.2198\n",
            "Epoch 60/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.2079 - val_loss: 0.2424\n",
            "Epoch 61/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.2177 - val_loss: 0.2441\n",
            "Epoch 62/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.2209 - val_loss: 0.2294\n",
            "Epoch 63/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.2126 - val_loss: 0.2332\n",
            "Epoch 64/300\n",
            "236/236 [==============================] - 81s 342ms/step - loss: 0.2112 - val_loss: 0.2429\n",
            "Epoch 65/300\n",
            "236/236 [==============================] - 80s 338ms/step - loss: 0.2166 - val_loss: 0.2187\n",
            "Epoch 66/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.2021 - val_loss: 0.2238\n",
            "Epoch 67/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.2004 - val_loss: 0.2189\n",
            "Epoch 68/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1911 - val_loss: 0.2331\n",
            "Epoch 69/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.2168 - val_loss: 0.2210\n",
            "Epoch 70/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1947 - val_loss: 0.2228\n",
            "Epoch 71/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.2251 - val_loss: 0.2218\n",
            "Epoch 72/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.2100 - val_loss: 0.2568\n",
            "Epoch 73/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.2191 - val_loss: 0.2388\n",
            "Epoch 74/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.2153 - val_loss: 0.2148\n",
            "Epoch 75/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1938 - val_loss: 0.2189\n",
            "Epoch 76/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1862 - val_loss: 0.2128\n",
            "Epoch 77/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1843 - val_loss: 0.2154\n",
            "Epoch 78/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1870 - val_loss: 0.2081\n",
            "Epoch 79/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1798 - val_loss: 0.2095\n",
            "Epoch 80/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1847 - val_loss: 0.2104\n",
            "Epoch 81/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1898 - val_loss: 0.2234\n",
            "Epoch 82/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.2015 - val_loss: 0.2495\n",
            "Epoch 83/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.2144 - val_loss: 0.2227\n",
            "Epoch 84/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1965 - val_loss: 0.2152\n",
            "Epoch 85/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1869 - val_loss: 0.2082\n",
            "Epoch 86/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1819 - val_loss: 0.2179\n",
            "Epoch 87/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1839 - val_loss: 0.2017\n",
            "Epoch 88/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1800 - val_loss: 0.2079\n",
            "Epoch 89/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1929 - val_loss: 0.2065\n",
            "Epoch 90/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1764 - val_loss: 0.2018\n",
            "Epoch 91/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1877 - val_loss: 0.2059\n",
            "Epoch 92/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1987 - val_loss: 0.2112\n",
            "Epoch 93/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1921 - val_loss: 0.2229\n",
            "Epoch 94/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1988 - val_loss: 0.2074\n",
            "Epoch 95/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1862 - val_loss: 0.2301\n",
            "Epoch 96/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1959 - val_loss: 0.2087\n",
            "Epoch 97/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1894 - val_loss: 0.2040\n",
            "\n",
            "Epoch 00097: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
            "Epoch 98/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1780 - val_loss: 0.1992\n",
            "Epoch 99/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1714 - val_loss: 0.2017\n",
            "Epoch 100/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1673 - val_loss: 0.1911\n",
            "Epoch 101/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1633 - val_loss: 0.1980\n",
            "Epoch 102/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1636 - val_loss: 0.1925\n",
            "Epoch 103/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1590 - val_loss: 0.1916\n",
            "Epoch 104/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1591 - val_loss: 0.1912\n",
            "Epoch 105/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1673 - val_loss: 0.2032\n",
            "Epoch 106/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1640 - val_loss: 0.1878\n",
            "Epoch 107/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1527 - val_loss: 0.1886\n",
            "Epoch 108/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1575 - val_loss: 0.1983\n",
            "Epoch 109/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1620 - val_loss: 0.1940\n",
            "Epoch 110/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1572 - val_loss: 0.1922\n",
            "Epoch 111/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1891 - val_loss: 0.1924\n",
            "Epoch 112/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1655 - val_loss: 0.1970\n",
            "Epoch 113/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1565 - val_loss: 0.1865\n",
            "Epoch 114/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1546 - val_loss: 0.1886\n",
            "Epoch 115/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1510 - val_loss: 0.1873\n",
            "Epoch 116/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1510 - val_loss: 0.1895\n",
            "Epoch 117/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1571 - val_loss: 0.1916\n",
            "Epoch 118/300\n",
            "236/236 [==============================] - 80s 339ms/step - loss: 0.1568 - val_loss: 0.1934\n",
            "Epoch 119/300\n",
            "236/236 [==============================] - 81s 341ms/step - loss: 0.1551 - val_loss: 0.1869\n",
            "Epoch 120/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1500 - val_loss: 0.1861\n",
            "Epoch 121/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.1463 - val_loss: 0.2018\n",
            "Epoch 122/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1587 - val_loss: 0.1907\n",
            "Epoch 123/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.1510 - val_loss: 0.1871\n",
            "Epoch 124/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1510 - val_loss: 0.2006\n",
            "Epoch 125/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1679 - val_loss: 0.1914\n",
            "Epoch 126/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1566 - val_loss: 0.1890\n",
            "Epoch 127/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.1504 - val_loss: 0.2229\n",
            "Epoch 128/300\n",
            "236/236 [==============================] - 82s 348ms/step - loss: 0.1728 - val_loss: 0.1932\n",
            "Epoch 129/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.1685 - val_loss: 0.2025\n",
            "Epoch 130/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.1665 - val_loss: 0.1901\n",
            "\n",
            "Epoch 00130: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
            "Epoch 131/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.1493 - val_loss: 0.1989\n",
            "Epoch 132/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1503 - val_loss: 0.1886\n",
            "Epoch 133/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.1455 - val_loss: 0.1800\n",
            "Epoch 134/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1381 - val_loss: 0.1779\n",
            "Epoch 135/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.1342 - val_loss: 0.1783\n",
            "Epoch 136/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.1322 - val_loss: 0.1800\n",
            "Epoch 137/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1309 - val_loss: 0.1789\n",
            "Epoch 138/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1357 - val_loss: 0.1810\n",
            "Epoch 139/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.1311 - val_loss: 0.1777\n",
            "Epoch 140/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1313 - val_loss: 0.1785\n",
            "Epoch 141/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1289 - val_loss: 0.1776\n",
            "Epoch 142/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.1280 - val_loss: 0.1775\n",
            "Epoch 143/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.1276 - val_loss: 0.1791\n",
            "Epoch 144/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1295 - val_loss: 0.1788\n",
            "Epoch 145/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1279 - val_loss: 0.1777\n",
            "Epoch 146/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1260 - val_loss: 0.1781\n",
            "Epoch 147/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1270 - val_loss: 0.1774\n",
            "Epoch 148/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1250 - val_loss: 0.1783\n",
            "Epoch 149/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1259 - val_loss: 0.1759\n",
            "Epoch 150/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1238 - val_loss: 0.1781\n",
            "Epoch 151/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1270 - val_loss: 0.1769\n",
            "Epoch 152/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1329 - val_loss: 0.1887\n",
            "Epoch 153/300\n",
            "236/236 [==============================] - 81s 345ms/step - loss: 0.1439 - val_loss: 0.1832\n",
            "Epoch 154/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1352 - val_loss: 0.1826\n",
            "Epoch 155/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1318 - val_loss: 0.1794\n",
            "Epoch 156/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1275 - val_loss: 0.1792\n",
            "Epoch 157/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1254 - val_loss: 0.1774\n",
            "Epoch 158/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1221 - val_loss: 0.1772\n",
            "Epoch 159/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1215 - val_loss: 0.1761\n",
            "\n",
            "Epoch 00159: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
            "Epoch 160/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1182 - val_loss: 0.1775\n",
            "Epoch 161/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1167 - val_loss: 0.1760\n",
            "Epoch 162/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1133 - val_loss: 0.1745\n",
            "Epoch 163/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1115 - val_loss: 0.1749\n",
            "Epoch 164/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1117 - val_loss: 0.1754\n",
            "Epoch 165/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1113 - val_loss: 0.1750\n",
            "Epoch 166/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1113 - val_loss: 0.1744\n",
            "Epoch 167/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1109 - val_loss: 0.1744\n",
            "Epoch 168/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1100 - val_loss: 0.1743\n",
            "Epoch 169/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1107 - val_loss: 0.1846\n",
            "Epoch 170/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1263 - val_loss: 0.1758\n",
            "Epoch 171/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1146 - val_loss: 0.1758\n",
            "Epoch 172/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1111 - val_loss: 0.1751\n",
            "Epoch 173/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1086 - val_loss: 0.1740\n",
            "Epoch 174/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1082 - val_loss: 0.1738\n",
            "Epoch 175/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1067 - val_loss: 0.1736\n",
            "Epoch 176/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1068 - val_loss: 0.1744\n",
            "Epoch 177/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1065 - val_loss: 0.1741\n",
            "Epoch 178/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1055 - val_loss: 0.1757\n",
            "Epoch 179/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1044 - val_loss: 0.1740\n",
            "Epoch 180/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.1047 - val_loss: 0.1755\n",
            "Epoch 181/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1042 - val_loss: 0.1740\n",
            "Epoch 182/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1038 - val_loss: 0.1743\n",
            "Epoch 183/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1027 - val_loss: 0.1745\n",
            "Epoch 184/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1032 - val_loss: 0.1743\n",
            "Epoch 185/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.1028 - val_loss: 0.1739\n",
            "\n",
            "Epoch 00185: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
            "Epoch 186/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.0991 - val_loss: 0.1754\n",
            "Epoch 187/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.0966 - val_loss: 0.1750\n",
            "Epoch 188/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.0960 - val_loss: 0.1735\n",
            "Epoch 189/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.0950 - val_loss: 0.1732\n",
            "Epoch 190/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.0943 - val_loss: 0.1737\n",
            "Epoch 191/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.0944 - val_loss: 0.1735\n",
            "Epoch 192/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.0943 - val_loss: 0.1735\n",
            "Epoch 193/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.0941 - val_loss: 0.1733\n",
            "Epoch 194/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.0928 - val_loss: 0.1738\n",
            "Epoch 195/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.0922 - val_loss: 0.1742\n",
            "Epoch 196/300\n",
            "236/236 [==============================] - 82s 348ms/step - loss: 0.0929 - val_loss: 0.1739\n",
            "Epoch 197/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.0914 - val_loss: 0.1738\n",
            "Epoch 198/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.0909 - val_loss: 0.1738\n",
            "Epoch 199/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.0905 - val_loss: 0.1739\n",
            "\n",
            "Epoch 00199: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
            "Epoch 200/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.0894 - val_loss: 0.1740\n",
            "Epoch 201/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.0859 - val_loss: 0.1736\n",
            "Epoch 202/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.0852 - val_loss: 0.1737\n",
            "Epoch 203/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.0846 - val_loss: 0.1732\n",
            "Epoch 204/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.0850 - val_loss: 0.1733\n",
            "Epoch 205/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.0834 - val_loss: 0.1736\n",
            "Epoch 206/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.0837 - val_loss: 0.1729\n",
            "Epoch 207/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.0835 - val_loss: 0.1734\n",
            "Epoch 208/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.0827 - val_loss: 0.1740\n",
            "Epoch 209/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.0822 - val_loss: 0.1734\n",
            "Epoch 210/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.0819 - val_loss: 0.1738\n",
            "Epoch 211/300\n",
            "236/236 [==============================] - 81s 345ms/step - loss: 0.0817 - val_loss: 0.1742\n",
            "Epoch 212/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.0814 - val_loss: 0.1739\n",
            "Epoch 213/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.0815 - val_loss: 0.1743\n",
            "Epoch 214/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.0808 - val_loss: 0.1743\n",
            "Epoch 215/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.0809 - val_loss: 0.1745\n",
            "Epoch 216/300\n",
            "236/236 [==============================] - 81s 344ms/step - loss: 0.0818 - val_loss: 0.1744\n",
            "\n",
            "Epoch 00216: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
            "Epoch 217/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.0782 - val_loss: 0.1740\n",
            "Epoch 218/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.0756 - val_loss: 0.1739\n",
            "Epoch 219/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.0752 - val_loss: 0.1738\n",
            "Epoch 220/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.0748 - val_loss: 0.1740\n",
            "Epoch 221/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.0746 - val_loss: 0.1744\n",
            "Epoch 222/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.0747 - val_loss: 0.1747\n",
            "Epoch 223/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.0743 - val_loss: 0.1744\n",
            "Epoch 224/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.0744 - val_loss: 0.1744\n",
            "Epoch 225/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.0740 - val_loss: 0.1743\n",
            "Epoch 226/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.0730 - val_loss: 0.1746\n",
            "\n",
            "Epoch 00226: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
            "Epoch 227/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.0720 - val_loss: 0.1741\n",
            "Epoch 228/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.0696 - val_loss: 0.1745\n",
            "Epoch 229/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.0697 - val_loss: 0.1744\n",
            "Epoch 230/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.0686 - val_loss: 0.1745\n",
            "Epoch 231/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.0684 - val_loss: 0.1748\n",
            "Epoch 232/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.0687 - val_loss: 0.1747\n",
            "Epoch 233/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.0689 - val_loss: 0.1747\n",
            "Epoch 234/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.0678 - val_loss: 0.1747\n",
            "Epoch 235/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.0684 - val_loss: 0.1746\n",
            "Epoch 236/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.0675 - val_loss: 0.1752\n",
            "\n",
            "Epoch 00236: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
            "Epoch 237/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.0667 - val_loss: 0.1745\n",
            "Epoch 238/300\n",
            "236/236 [==============================] - 81s 343ms/step - loss: 0.0649 - val_loss: 0.1746\n",
            "Epoch 239/300\n",
            " 53/236 [=====>........................] - ETA: 58s - loss: 0.0642"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m73VwznGBh5R"
      },
      "source": [
        "print(\"mae:\", oof.eval(\"abs(pressure - pred)\").mean())\n",
        "print(\"mae inspiratory:\", oof.query(\"u_out == 0\").eval(\"abs(pressure - pred)\").mean())\n",
        "print(\"mae expiratory :\", oof.query(\"u_out == 1\").eval(\"abs(pressure - pred)\").mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo8ooYNAQsCy"
      },
      "source": [
        "***\n",
        "## sub generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSGjBh2qQraV"
      },
      "source": [
        "all_preds = list()\n",
        "test_tf = tf.convert_to_tensor(test, dtype=tf.float32)\n",
        "\n",
        "for model in models_by_fold:\n",
        "    preds = model.call(test_tf, training=False).numpy().squeeze().ravel()\n",
        "    all_preds.append(preds)\n",
        "\n",
        "test_raw[\"pressure\"] = np.mean(all_preds, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpBQRKIXi7Qo"
      },
      "source": [
        "# saves final sub\n",
        "sub = pd.merge(submission[\"id\"], test_raw[[\"id\",\"pressure\"]], how=\"left\", on=\"id\")\n",
        "sub[\"pressure\"] = sub[\"pressure\"].fillna(0)\n",
        "sub.to_csv(f\"{subs_path}/sub_lstm.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81gmgjMIfjAT"
      },
      "source": [
        "# saves oof preds\n",
        "oof.to_csv(f\"{results_path}/oof_lstm.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo6W9e1QxlOV"
      },
      "source": [
        "# saves each model preds (pseudo labels)\n",
        "for fold,preds in enumerate(all_preds):\n",
        "    _sub = submission.copy()\n",
        "    _test = test_raw[[\"id\",\"pressure\"]].copy()\n",
        "    _test[\"pressure\"] = preds\n",
        "    _sub = pd.merge(_sub[\"id\"], _test[[\"id\",\"pressure\"]], how=\"left\", on=\"id\")\n",
        "    _sub[\"pressure\"] = _sub[\"pressure\"].fillna(0)\n",
        "    _sub.to_csv(f\"{results_path}/plabels_lstm_{fold}.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-EK2rCThxOr"
      },
      "source": [
        "***"
      ]
    }
  ]
}